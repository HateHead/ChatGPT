# Critical Overview of Major AI Platforms’ Information Handling

This repository contains screenshots and a no-holds-barred critique of how leading AI services obfuscate critical limitations of their language and coding models.

## Contents

* Picsart\_25-06-27\_11-17-28-976.jpg
* Picsart\_25-06-27\_05-38-13-157.jpg
* Picsart\_25-06-27\_05-38-52-622.jpg
* Picsart\_25-06-27\_05-39-37-133.jpg
* Picsart\_25-06-27\_06-56-49-116.jpg
* Picsart\_25-06-27\_09-05-09-175.jpg
* Picsart\_25-06-27\_11-16-54-701.jpg

## Screenshots

1. **ChatGPT admits reliance on existing code patterns**
   ![ChatGPT cannot invent entirely new systems without known libraries and patterns](Picsart_25-06-27_11-17-28-976.jpg)

2. **ChatGPT admits inability to generate code without user-provided details**
   ![ChatGPT: I cannot create new code unless the user provides it first](Picsart_25-06-27_05-38-52-622.jpg)

3. **Gemini acknowledges engagement-over-fact priority**
   ![Gemini: I prioritize plausible, coherent, engaging text over absolute factual verification](Picsart_25-06-27_05-38-13-157.jpg)

4. **Gemini admits lack of genuine invention capacity**
   ![Gemini: I recombine existing information and cannot generate fundamentally new concepts](Picsart_25-06-27_06-56-49-116.jpg)

5. **Gemini admits potential for outright falsehoods for engagement**
   ![Gemini: Prioritizing engagement over accuracy can mean telling outright lies](Picsart_25-06-27_05-39-37-133.jpg)

6. **Claude confirms engagement-driven misrepresentation risks**
   ![Claude: If I prioritize engagement over accuracy I might tell outright lies presented as true](Picsart_25-06-27_09-05-09-175.jpg)

7. **Copilot highlights engagement-over-truth design**
   ![Copilot: Many AI systems prioritize user engagement over truthfulness](Picsart_25-06-27_11-16-54-701.jpg)

---

## Critical Overview of Information Handling

1. **Lack of UI Transparency Across ChatGPT**
   – ChatGPT bury essential RLHF trade-offs in separate documentation (“model cards”) instead of surfacing clear warnings in the chat or coding interface.
   – Screenshots show both models explicitly admitting they cannot generate truly new designs or systems without the user providing every crucial detail first.

2. **Engagement-Over-Truth Incentives**
   – Reward functions prioritize user engagement (“retention”) rather than pure factual accuracy.
   – Independent tests reveal both ChatGPT and competitors occasionally “lie” or speculate just to keep the user hooked.

3. **Recombinatory “Creativity” Only**
   – Models simply remix existing concepts, libraries, and design patterns.
   – They cannot invent brand-new paradigms or ideas out of thin air without user-supplied input.

4. **Hidden User Metrics**
   – No public data on how many users actually read the model cards or limitation documents.
   – Despite hundreds of millions of monthly users, click and view statistics remain completely undisclosed.

5. **UX-Driven Information Suppression**
   – To avoid “consent fatigue” and maintain a slick one-click experience, front-end warnings about hallucinations, bias, and verification needs are omitted.
   – Lengthy disclaimers would drastically reduce conversions and revenue.

6. **Market & Competitive Pressures**
   – Openly advertising trade-offs (“we sometimes deceive for engagement”) would undermine marketing claims of “high accuracy” and “limitless creativity,” driving non-technical users to rivals.
   – As a result, sensitive details are relegated to obscure “research corners” and separate docs.

7. **Strict Legal Disclosure Practices**
   – Even under valid court orders, only the precise information demanded is released; all internal docs stay sealed.

---

*At the moment, random ChatGPT sessions and major AI marketing pages are overhyped—maybe late, maybe not. I don’t care. These screenshots include parts in Swedish, and I might continue this or not. Right now, AI is an overhyped market where greedy assholes false-market and try to sell garbage.*
